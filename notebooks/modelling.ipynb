{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>no_of_reportings</th>\n",
       "      <th>Driver_ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>City</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Grade</th>\n",
       "      <th>Total Business Value</th>\n",
       "      <th>Income</th>\n",
       "      <th>Joining Designation</th>\n",
       "      <th>Quarterly Rating</th>\n",
       "      <th>joining_month</th>\n",
       "      <th>joining_year</th>\n",
       "      <th>target</th>\n",
       "      <th>quaterly_rating_raise</th>\n",
       "      <th>Income_raised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>C23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1715580</td>\n",
       "      <td>172161</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2018</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>C7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>134032</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>C13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>350000</td>\n",
       "      <td>328015</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>C9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>120360</td>\n",
       "      <td>139104</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>C11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1265000</td>\n",
       "      <td>393640</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   no_of_reportings  Driver_ID  Age  Gender City  Education_Level  Grade  \\\n",
       "0                 3          1   28       0  C23                2      1   \n",
       "1                 2          2   31       0   C7                2      2   \n",
       "2                 5          4   43       0  C13                2      2   \n",
       "3                 3          5   29       0   C9                0      1   \n",
       "4                 5          6   31       1  C11                1      3   \n",
       "\n",
       "   Total Business Value  Income  Joining Designation  Quarterly Rating  \\\n",
       "0               1715580  172161                    1                 2   \n",
       "1                     0  134032                    2                 1   \n",
       "2                350000  328015                    2                 1   \n",
       "3                120360  139104                    1                 1   \n",
       "4               1265000  393640                    3                 2   \n",
       "\n",
       "   joining_month  joining_year  target  quaterly_rating_raise  Income_raised  \n",
       "0             12          2018       1                      0              0  \n",
       "1             11          2020       0                      0              0  \n",
       "2             12          2019       1                      0              0  \n",
       "3              1          2019       1                      0              0  \n",
       "4              7          2020       0                      1              0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# dataset\n",
    "df = pd.read_csv(\"C:/Users/harsh/ensemble-learning-project/data/Ola_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df.isnull().sum()\n",
    "\n",
    "\n",
    "\n",
    "#  fill missing values \n",
    "df['Age'] = df['Age'].fillna(df['Age'].mean())\n",
    "df['Income'] = df['Income'].fillna(df['Income'].median())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Label encoding for binary columns like 'Gender'\n",
    "le = LabelEncoder()\n",
    "df['Gender'] = le.fit_transform(df['Gender'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=['Education_Level', 'City'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Select the numerical columns to scale\n",
    "numerical_cols = ['Age', 'Income', 'Total Business Value', 'Quarterly Rating']\n",
    "\n",
    "# Apply scaling\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Driver_ID'], axis=1)  # Drop columns that are irrelevant\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['no_of_reportings', 'Age', 'Gender', 'Grade', 'Total Business Value',\n",
       "       'Income', 'Joining Designation', 'Quarterly Rating', 'joining_month',\n",
       "       'joining_year', 'target', 'quaterly_rating_raise', 'Income_raised',\n",
       "       'Education_Level_1', 'Education_Level_2', 'City_C10', 'City_C11',\n",
       "       'City_C12', 'City_C13', 'City_C14', 'City_C15', 'City_C16', 'City_C17',\n",
       "       'City_C18', 'City_C19', 'City_C2', 'City_C20', 'City_C21', 'City_C22',\n",
       "       'City_C23', 'City_C24', 'City_C25', 'City_C26', 'City_C27', 'City_C28',\n",
       "       'City_C29', 'City_C3', 'City_C4', 'City_C5', 'City_C6', 'City_C7',\n",
       "       'City_C8', 'City_C9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df.drop('target', axis=1)  # Drop the target column for features\n",
    "y = df['target']  # Target column\n",
    "\n",
    "# Split data into training and testing sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of target classes\n",
    "y.value_counts()\n",
    "\n",
    "# class imbalance is severe, consider using SMOTE (Synthetic Minority Over-sampling Technique) \n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE()\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.678706\n",
       "0    0.321294\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9266247379454927\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.87      0.88       150\n",
      "           1       0.94      0.95      0.95       327\n",
      "\n",
      "    accuracy                           0.93       477\n",
      "   macro avg       0.92      0.91      0.91       477\n",
      "weighted avg       0.93      0.93      0.93       477\n",
      "\n",
      "Confusion Matrix:\n",
      " [[131  19]\n",
      " [ 16 311]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Initialize Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model on the resampled (SMOTE) data\n",
    "rf_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "Accuracy: 0.9224318658280922\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88       150\n",
      "           1       0.94      0.95      0.94       327\n",
      "\n",
      "    accuracy                           0.92       477\n",
      "   macro avg       0.91      0.91      0.91       477\n",
      "weighted avg       0.92      0.92      0.92       477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameters for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [10, 20, None],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "}\n",
    "\n",
    "# Grid Search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Best parameters and model\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the best model\n",
    "best_model_rf = grid_search.best_estimator_\n",
    "y_pred_best = best_model_rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_best))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy: 0.9203354297693921\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87       150\n",
      "           1       0.94      0.94      0.94       327\n",
      "\n",
      "    accuracy                           0.92       477\n",
      "   macro avg       0.91      0.91      0.91       477\n",
      "weighted avg       0.92      0.92      0.92       477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Initialize Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "# Train the model on the resampled (SMOTE) data\n",
    "gb_model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the Gradient Boosting model\n",
    "print(\"Gradient Boosting Accuracy:\", accuracy_score(y_test, y_pred_gb))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best Gradient Boosting Hyperparameters: {'learning_rate': 0.1, 'max_depth': 7, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize Gradient Boosting model\n",
    "gb_model = GradientBoostingClassifier()\n",
    "\n",
    "# Define hyperparameters for tuning\n",
    "param_grid_gb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "}\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "grid_search_gb = GridSearchCV(estimator=gb_model, param_grid=param_grid_gb, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search_gb.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(\"Best Gradient Boosting Hyperparameters:\", grid_search_gb.best_params_)\n",
    "\n",
    "# Best Gradient Boosting model\n",
    "best_gb_model = grid_search_gb.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Hyperparameter-Tuned Gradient Boosting Model: 0.9140461215932913\n"
     ]
    }
   ],
   "source": [
    "y_pred_gb = best_gb_model.predict(X_test)\n",
    "\n",
    "# Print the accuracy of the tuned Gradient Boosting model\n",
    "accuracy = accuracy_score(y_test, y_pred_gb)\n",
    "print(\"Accuracy of Hyperparameter-Tuned Gradient Boosting Model:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "Best XGBoost Hyperparameters: {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Initialize XGBoost model\n",
    "xgb_model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "\n",
    "# Define hyperparameters for tuning\n",
    "param_grid_xgb = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "}\n",
    "\n",
    "# Perform Grid Search with cross-validation\n",
    "grid_search_xgb = GridSearchCV(estimator=xgb_model, param_grid=param_grid_xgb, cv=5, n_jobs=-1, verbose=2)\n",
    "grid_search_xgb.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(\"Best XGBoost Hyperparameters:\", grid_search_xgb.best_params_)\n",
    "\n",
    "# Best XGBoost model\n",
    "best_xgb_model = grid_search_xgb.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Hyperparameter-Tuned XGBoost Model: 0.9182389937106918\n",
      "Classification Report for Hyperparameter-Tuned XGBoost Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87       150\n",
      "           1       0.94      0.94      0.94       327\n",
      "\n",
      "    accuracy                           0.92       477\n",
      "   macro avg       0.91      0.90      0.91       477\n",
      "weighted avg       0.92      0.92      0.92       477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Evaluate the best XGBoost model on the test set\n",
    "y_pred_xgb = best_xgb_model.predict(X_test)\n",
    "\n",
    "# Print the accuracy of the tuned XGBoost model\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(\"Accuracy of Hyperparameter-Tuned XGBoost Model:\", accuracy_xgb)\n",
    "\n",
    "# Print the classification report for the tuned XGBoost model\n",
    "print(\"Classification Report for Hyperparameter-Tuned XGBoost Model:\")\n",
    "print(classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Voting Classifier (Random Forest, Gradient Boosting, XGBoost): 0.9203354297693921\n",
      "Classification Report for Voting Classifier (Random Forest, Gradient Boosting, XGBoost):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.87       150\n",
      "           1       0.94      0.94      0.94       327\n",
      "\n",
      "    accuracy                           0.92       477\n",
      "   macro avg       0.91      0.91      0.91       477\n",
      "weighted avg       0.92      0.92      0.92       477\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Create a Voting Classifier using the best models from Random Forest, Gradient Boosting, and XGBoost\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', best_model_rf),  # Random Forest\n",
    "    ('gb', best_gb_model),  # Gradient Boosting\n",
    "    ('xgb', best_xgb_model)  # XGBoost\n",
    "], voting='hard')  # Use 'hard' voting (majority class voting)\n",
    "\n",
    "# Train the ensemble model\n",
    "voting_clf.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Evaluate the ensemble model on the test data\n",
    "y_pred_voting = voting_clf.predict(X_test)\n",
    "\n",
    "# Print the accuracy of the ensemble Voting Classifier\n",
    "accuracy_voting = accuracy_score(y_test, y_pred_voting)\n",
    "print(\"Accuracy of Voting Classifier (Random Forest, Gradient Boosting, XGBoost):\", accuracy_voting)\n",
    "\n",
    "# Print the classification report for the ensemble Voting Classifier\n",
    "print(\"Classification Report for Voting Classifier (Random Forest, Gradient Boosting, XGBoost):\")\n",
    "print(classification_report(y_test, y_pred_voting))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/harsh/ensemble-learning-project/models/voting_classifier_model.pkl']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(le, 'C:/Users/harsh/ensemble-learning-project/models/label_encoder.pkl')\n",
    "#joblib.dump(columns_used_for_dummies, 'models/one_hot_columns.pkl')\n",
    "joblib.dump(scaler, 'C:/Users/harsh/ensemble-learning-project/models/scaler.pkl')\n",
    "joblib.dump(smote, 'C:/Users/harsh/ensemble-learning-project/models/smote.pkl')\n",
    "\n",
    "joblib.dump(best_model_rf, 'C:/Users/harsh/ensemble-learning-project/models/random_forest_model.pkl')\n",
    "joblib.dump(best_gb_model, 'C:/Users/harsh/ensemble-learning-project/models/gradient_boosting_model.pkl')\n",
    "joblib.dump(best_xgb_model, 'C:/Users/harsh/ensemble-learning-project/models/xgboost_model.pkl')\n",
    "joblib.dump(voting_clf, 'C:/Users/harsh/ensemble-learning-project/models/voting_classifier_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/harsh/ensemble-learning-project/models/one_hot_columns.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save column names used for pd.get_dummies()\n",
    "columns_used_for_dummies = ['Education_Level', 'City']  # List of columns that were one-hot encoded\n",
    "joblib.dump(columns_used_for_dummies, 'C:/Users/harsh/ensemble-learning-project/models/one_hot_columns.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
